{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPLORE PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = \"./categories/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_with_depth(\n",
    "    node: dict, name: str, path: str, parent: str, ancestor: str, depth: int = 0\n",
    "):\n",
    "    innerdata = {\n",
    "        \"name\": name,\n",
    "        \"parent\": parent,\n",
    "        \"ancestor\": ancestor if depth > 0 else None,\n",
    "        \"is_leaf\": False,\n",
    "        \"depth\": depth,\n",
    "        \"url\": node[\"url\"],\n",
    "        \"path\": path,\n",
    "        \"inner\": {},\n",
    "    }\n",
    "\n",
    "    if not node[\"inner\"]:\n",
    "        innerdata[\"is_leaf\"] = True\n",
    "        return innerdata\n",
    "\n",
    "    for category in node[\"inner\"]:\n",
    "        new_path = f\"{path}/{category}\"\n",
    "        subdata = explore_with_depth(\n",
    "            node[\"inner\"][category],\n",
    "            category,\n",
    "            new_path,\n",
    "            innerdata[\"name\"],\n",
    "            ancestor,\n",
    "            depth + 1,\n",
    "        )\n",
    "        innerdata[\"inner\"][category] = subdata\n",
    "    return innerdata\n",
    "\n",
    "\n",
    "filenames = [\n",
    "    os.path.join(OUT_DIR, filename)\n",
    "    for filename in os.listdir(OUT_DIR)\n",
    "    if \".json\" in filename\n",
    "    and \"\\uf07c\" not in filename\n",
    "    and \"processed\" not in filename\n",
    "    and \"final\" not in filename\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {}\n",
    "for old_filename in filenames:\n",
    "    new_filename = old_filename.split(\".json\")[0] + \".processed.json\"\n",
    "    with open(old_filename, \"r\", encoding=\"utf-8\") as read_file, open(\n",
    "        new_filename, \"w\"\n",
    "    ) as write_file:\n",
    "        jsondata = json.load(read_file)\n",
    "        category_name = jsondata[\"path\"]\n",
    "        processed_jsondata = explore_with_depth(\n",
    "            jsondata,\n",
    "            category_name,\n",
    "            category_name,\n",
    "            category_name,\n",
    "            category_name,\n",
    "        )\n",
    "        dict_data[category_name] = processed_jsondata\n",
    "        json.dump(\n",
    "            processed_jsondata,\n",
    "            write_file,\n",
    "            indent=2,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_data = []\n",
    "processed = set()\n",
    "\n",
    "\n",
    "def process_node(node):\n",
    "    k = f\"[depth={node['depth']}][name={node['name']}]\"\n",
    "    if k in processed:\n",
    "        return []\n",
    "\n",
    "    processed.add(k)\n",
    "\n",
    "    if not node:\n",
    "        return []\n",
    "\n",
    "    name = node[\"name\"]\n",
    "    parent = node[\"parent\"]\n",
    "    ancestor = node[\"ancestor\"]\n",
    "    is_leaf = node[\"is_leaf\"]\n",
    "    depth = node[\"depth\"]\n",
    "    url = node[\"url\"]\n",
    "    path = node[\"path\"]\n",
    "    inner = node[\"inner\"]\n",
    "\n",
    "    row = [name, depth, ancestor, parent, path, url, is_leaf]\n",
    "    output = [row]\n",
    "\n",
    "    for category in inner:\n",
    "        innerdata = process_node(inner[category])\n",
    "        output += innerdata\n",
    "    return output\n",
    "\n",
    "\n",
    "for category_name in dict_data:\n",
    "    ancestor = category_name\n",
    "    node = dict_data[category_name]\n",
    "    lst_data += process_node(node)\n",
    "\n",
    "\n",
    "with open(os.path.join(OUT_DIR, \"final.db.json\"), \"w\") as write_file:\n",
    "    json.dump(lst_data, write_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "INSERT INTO \"scraping\".\"amazon_categories\" (\n",
    "    name, depth, ancestor, parent, path, url, is_leaf\n",
    ") VALUES ($1, $2, $3, $4, $5, $6, $7);\n",
    "\"\"\"\n",
    "import asyncpg\n",
    "\n",
    "async with asyncpg.create_pool(dsn=os.getenv(\"POSTGRESQL_CONN_STR\")) as pool:\n",
    "    async with pool.acquire() as conn:\n",
    "        await conn.executemany(query, lst_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
